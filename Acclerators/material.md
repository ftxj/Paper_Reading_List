Poly Materials

- [Book](#book)
- [People](#people)
- [Course](#course)
- [Conference](#conference)
- [Acclerator Classification](#acclerator-classification)
- [Papers](#papers)
  - [Acclerator for Deep Learning](#acclerator-for-deep-learning)
  - [Acclerator for Machine Learning](#acclerator-for-machine-learning)
  - [Acclerator for Gene](#acclerator-for-gene)
  - [Acclerator for Graph Processing](#acclerator-for-graph-processing)
  - [Acclerator for Sparse Data(SpMM, SpGemm, Sparse DNN)](#acclerator-for-sparse-dataspmm-spgemm-sparse-dnn)
  - [Acclerator for General Purpose](#acclerator-for-general-purpose)
  - [Acclerator for Others](#acclerator-for-others)
  - [SW/HW Co-Design and Domain Acclerator Compiler](#swhw-co-design-and-domain-acclerator-compiler)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>

# Book

* (2001) Optimizing Compilers for Modern Architectures: A Dependence-based Approach [[pdf]](Dependence-Approach-Compiler.pdf)


# People
* [Xuehai Qian](http://alchem.usc.edu/portal/index.html)(钱学海) Graph Processing, Machine Learning Accleration

# Course

# Conference
* MICRO
* ISCA
* ASPLOS
* HPCA

# Acclerator Classification
* ASIC
* FPGA
* NDP
* PIM
* Dataflow
* Spatial

# Papers

## Acclerator for Deep Learning
| **Date** | **Paper** | **Focused On** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS | Statistical Robustness of Markov Chain Monte Carlo Accelerators [[paper]](https://users.cs.duke.edu/~alvy/papers/robustness_asplos21.pdf)  | 马尔可夫 |  |
| 2021 ISCA | RaPiD: AI Accelerator for Ultra-Low Precision Training and Inference   |  |  |
| 2021 ISCA | REDUCT: Keep It Close, Keep It Cool! - Scaling DNN Inference on Multi-Core CPUs with Near-Cache Compute   |  NDP |  |
| 2021 ISCA | FORMS: Fine-Grained Polarized ReRAM-Based In-Situ Computation for Mixed-Signal DNN Accelerator |  PIM |  |
| 2021 ISCA | Enabling Compute-Communication Overlap in Distributed Deep Learning Training Platforms |   |  |
| 2021 ISCA | SPACE: Locality-Aware Processing in Heterogeneous Memory for Personalized Recommendations |   |  |
| 2021 ISCA | Cambricon-Q: A Hybrid Architecture for Efficient Training |   |  |
| 2021 ISCA | NASA: Accelerating Neural Network Design with a NAS Processor |   |  |
| 2021 ISCA | NN-Baton: DNN Workload Orchestration and Chiplet Granularity Exploration for Multichip Accelerators |   |  |

----

## Acclerator for Machine Learning
| **Date** | **Paper** | **Focused On** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS | Statistical Robustness of Markov Chain Monte Carlo Accelerators [[paper]](https://users.cs.duke.edu/~alvy/papers/robustness_asplos21.pdf)  | 马尔可夫 |  |

----


## Acclerator for Gene
| **Date** | **Paper** | **Focused On** | **Notes** |
| --- | --- | --- | --- |
| 2021 ISCA | Sieve: Scalable In-Situ DRAM-Based Accelerator Designs for Massively Parallel k-mer Matching | NDP |  |
| 2021 ISCA | Accelerated Seeding for Genome Sequence Alignment with Enumerated Radix Trees |  |  |

----

## Acclerator for Graph Processing
| **Date** | **Paper** | **Main Contribute** | **Notes** |
| --- | --- | --- | --- |
| 2021 ISCA | FlexMiner: A Pattern-Aware Accelerator for Graph Pattern Mining |  |  |
| 2021 ISCA | PolyGraph: Exposing the Value of Flexibility for Graph Processing Accelerators |  |  |
| 2021 ISCA | Large-Scale Graph Processing on FPGAs with Caches for Thousands of Simultaneous Misses |  |  |


----

## Acclerator for Sparse Data(SpMM, SpGemm, Sparse DNN)
| **Date** | **Paper** | **Focused on** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS |Gamma: Leveraging Gustavson’s Algorithm to Accelerate Sparse Matrix Multiplication [[paper]](https://dl.acm.org/doi/abs/10.1145/3445814.3446702)  | SpGEMM |  |
| 2021 ISCA | SpZip: Architectural Support for Effective Data Compression In Irregular Applications |  |  |
| 2021 ISCA | Dual-Side Sparse Tensor Core |  |  |
| 2021 ISCA | RingCNN: Exploiting Algebraically-Sparse Ring Tensors for Energy-Efficient CNN-Based Computational Imaging |  |  |
| 2021 ISCA | GoSPA: An Energy-Efficient High-Performance Globally Optimized SParse Convolutional Neural Network Accelerator |  |  |

----

## Acclerator for General Purpose
| **Date** | **Paper** | **Focused On** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS | DiAG: A Dataflow-Inspired Architecture for General-Purpose Processors [[paper]](https://dl.acm.org/doi/abs/10.1145/3445814.3446703)  | 利用设计加速器的思想加速Dataflow架构 |  |
| 2021 ISCA | Aurochs: An Architecture for Dataflow Threads | |  |
| 2021 ISCA | SNAFU: An Ultra-Low-Power, Energy-Minimal CGRA-Generation Framework and Architecture | |  |
| 2021 ISCA | SARA: Scaling a Reconfigurable Dataflow Accelerator | |  |

----

## Acclerator for Others
| **Date** | **Paper** | **Domain** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS | Robomorphic Computing: A Design Methodology for Domain-Specific Accelerators Parameterized by Robot Morphology [[paper]](https://dl.acm.org/doi/10.1145/3445814.3446746)  | 机器人 |  |
| 2021 ISCA | PipeZK: Accelerating Zero-Knowledge Proof with a Pipelined Architecture | 密码学/区块链 |  |

----

## SW/HW Co-Design and Domain Acclerator Compiler
| **Date** | **Paper** | **Domain** | **Notes** |
| --- | --- | --- | --- |
| 2021 ASPLOS | Mind Mappings: Enabling Efficient Algorithm-Accelerator Mapping Space Search [[paper]](https://arxiv.org/abs/2103.01489)  | Algorithm-Accelrator mapping |  |
| 2021 ASPLOS | Analytical Characterization and Design Space Exploration for Optimization of CNNs [[paper]](https://arxiv.org/abs/2101.09808)  | CNN Schedule |  |
| 2021 ISCA | Communication Algorithm-Architecture Co-Design for Distributed Deep Learning   |  |  |
| 2021 ISCA | Taming the Zoo: The Unified GraphIt Compiler Framework for Novel Architectures   |  GraphIt |  |
| 2021 ISCA | CoSA: Scheduling by Constrained Optimization for Spatial Accelerators   | Scheduling |  |
| 2021 ISCA | η-LSTM: Co-Designing Highly-Efficient Large LSTM Training via Exploiting Memory-Saving and Architectural Design Opportunities | LSTM |  |
| 2021 ISCA | ELSA: Hardware-Software Co-Design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks | Attention |  |
| 2021 ISCA | TENET: A Framework for Modeling Tensor Dataflow Based on Relation-Centric Notation | |  |
| 2021 ISCA | HASCO: Towards Agile HArdware and Software CO-design for Tensor Computation | |  |


----
